import sqlite3
import json
import csv
import sys
import os
import argparse

sys.path.append(os.getcwd())
from riskbot.config import RISK_DB_PATH

def build_dataset(output_file: str, min_confidence: float = 0.7):
    print(f"Building training set (min_conf={min_confidence})...")
    conn = sqlite3.connect(RISK_DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Fetch labeled rows
    # We only want rows where label_value is 0 or 1 (ignore NULL)
    # And confidence is high enough (if present)
    cursor.execute("""
        SELECT feature_version, features_json, label_value, label_confidence
        FROM pr_runs
        WHERE label_value IS NOT NULL
    """)
    rows = cursor.fetchall()
    
    if not rows:
        print("No labeled data found.")
        return

    data = []
    feature_keys = set()
    
    count = 0
    skipped_conf = 0
    skipped_ver = 0
    
    for r in rows:
        # Confidence Filter
        conf = r['label_confidence']
        # If confidence is missing (None), assume 1.0 (manual label) or 0.5?
        # User schema implies it might be populated. If NULL, allow it? 
        # User said "Use only rows where label_confidence >= min_high_confidence".
        # Let's assume if NULL, it's manually labeled = 1.0? 
        # Or if generated by weak heuristics = low.
        # Safe default: if NULL, exclude? Or if NULL, assume high?
        # Let's assume manual input (label_value set directly) implies high confidence unless stated otherwise.
        if conf is not None and conf < min_confidence:
            skipped_conf += 1
            continue
            
        # Version Check (Optional, but good practice)
        # if r['feature_version'] != 'v6':
        #     skipped_ver += 1
        #     continue
            
        try:
            feats = json.loads(r['features_json'])
            # Flatten features
            # We only want numeric fields for logistic regression
            # Typically: churn_score, critical_path_score, etc.
            # Exclude debug fields or strings
            
            row_dict = {}
            for k, v in feats.items():
                if isinstance(v, (int, float)) and not isinstance(v, bool):
                     row_dict[k] = v
                     feature_keys.add(k)
            
            row_dict["label"] = int(r['label_value'])
            data.append(row_dict)
            count += 1
            
        except Exception as e:
            print(f"Error parsing validation row: {e}")
            continue
            
    conn.close()
    
    if not data:
        print("No valid rows after filtering.")
        return

    # Sort keys to ensure stable column order
    sorted_keys = sorted(list(feature_keys))
    header = ["label"] + sorted_keys
    
    print(f"Writing {count} rows to {output_file}...")
    print(f"Features: {sorted_keys}")
    
    with open(output_file, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()
        for row in data:
            writer.writerow(row)
            
    print("Done.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--out", default="training_data.csv")
    parser.add_argument("--min-conf", type=float, default=0.7)
    args = parser.parse_args()
    build_dataset(args.out, args.min_conf)
